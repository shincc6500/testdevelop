import requests
from bs4 import BeautifulSoup 
import re
from crawled_data.models import BoardData

def crawl_and_save(cntns_no):
    url = f"https://www.nongsaro.go.kr/portal/ps/psb/psbl/workScheduleDtl.ps?menuId=PS00087&cntntsNo={cntns_no}&sKidofcomdtySeCode=FC01"  # í¬ë¡¤ë§í•  ì›¹ì‚¬ì´íŠ¸ URL
    
    # ì›¹ í˜ì´ì§€ ìš”ì²­
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        # HTML íŒŒì‹±
        soup = BeautifulSoup(response.text, "html.parser")

        # id="contents"ì¸ div ìš”ì†Œ ì°¾ê¸°
        contents_div = soup.find("div", id="contents")

        # âœ… floatDiv ì•ˆì˜ h4 íƒœê·¸ ê°’ ê°€ì ¸ì˜¤ê¸°
        h4_tag = soup.select_one("div.floatDiv h4")  # floatDiv ë‚´ë¶€ì˜ h4 íƒœê·¸ ì„ íƒ
        vegetable_name = h4_tag.text.strip() if h4_tag else "ì´ë¦„ ì—†ìŒ"  # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ê³µë°± ì œê±°

        # âœ… <script> íƒœê·¸ì—ì„œ colSpanVal ê°’ ì¶”ì¶œ
        script_text = " ".join([script.text for script in soup.find_all("script") if script.text])
        colspan_values = re.findall(r'console\.log\("colSpanVal\s*:\s*"\s*\+\s*"(\d+)"\);', script_text)

        print("ğŸ“Œ ì¶”ì¶œëœ colSpanVal ê°’:", colspan_values)  # ['4', '4', '3', '5', ...]

        # âœ… <script> íƒœê·¸ ì „ì²´ë¥¼ ì£¼ì„ ì²˜ë¦¬
        for script in soup.find_all("script"):
            commented_script = f"<!-- {script} -->"  # script íƒœê·¸ ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì£¼ì„ ì²˜ë¦¬
            script.replace_with(BeautifulSoup(commented_script, "html.parser"))  # ë³€ê²½ëœ ë‚´ìš©ì„ ì ìš©

        if contents_div:
            # BoardData ëª¨ë¸ì— ì €ì¥
            BoardData.objects.create(tag=str(contents_div), vegetablename=vegetable_name)

            print("ğŸŒ± ì±„ì†Œ ì´ë¦„:", vegetable_name)  
            print(str(contents_div))
            print("\nâœ… í¬ë¡¤ë§ ë° ì €ì¥ ì™„ë£Œ!")
        else:
            print("âš ï¸ 'contents' IDë¥¼ ê°€ì§„ divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# crawl_and_save('')  # ì›í•˜ëŠ” ì¸ìë¥¼ ì „ë‹¬í•´ì„œ ì‹¤í–‰

















# import requests
# from bs4 import BeautifulSoup 
# import re
# from crawled_data.models import BoardData

# def crawl_and_save(cntns_no):
#     url = f"https://www.nongsaro.go.kr/portal/ps/psb/psbl/workScheduleDtl.ps?menuId=PS00087&cntntsNo={cntns_no}&sKidofcomdtySeCode=FC01"  # í¬ë¡¤ë§í•  ì›¹ì‚¬ì´íŠ¸ URL
    
#     # ì›¹ í˜ì´ì§€ ìš”ì²­
#     headers = {"User-Agent": "Mozilla/5.0"}
#     response = requests.get(url, headers=headers)

#     if response.status_code == 200:
#         # HTML íŒŒì‹±
#         soup = BeautifulSoup(response.text, "html.parser")

#         # id="contents"ì¸ div ìš”ì†Œ ì°¾ê¸°
#         contents_div = soup.find("div", id="contents")

#         # âœ… <script> íƒœê·¸ì—ì„œ colSpanVal ê°’ ì¶”ì¶œ
#         script_text = " ".join([script.text for script in soup.find_all("script") if script.text])
#         colspan_values = re.findall(r'console\.log\("colSpanVal\s*:\s*"\s*\+\s*"(\d+)"\);', script_text)

#         print("ğŸ“Œ ì¶”ì¶œëœ colSpanVal ê°’:", colspan_values)  # ['4', '4', '3', '5', ...]

#         # âœ… <script> íƒœê·¸ ì „ì²´ë¥¼ ì£¼ì„ ì²˜ë¦¬
#         for script in soup.find_all("script"):
#             commented_script = f"<!-- {script} -->"  # script íƒœê·¸ ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì£¼ì„ ì²˜ë¦¬
#             script.replace_with(BeautifulSoup(commented_script, "html.parser"))  # ë³€ê²½ëœ ë‚´ìš©ì„ ì ìš©

                
#         if contents_div:
#             # # ê¸°ë³¸ HTML êµ¬ì¡°ì— í¬ë¡¤ë§í•œ ë‚´ìš©ì„ í¬í•¨
#             # html_content = f"""
#             # <!DOCTYPE html>
#             # <html lang="ko">
#             # <head>
#             #     <meta charset="UTF-8">
#             #     <meta name="viewport" content="width=device-width, initial-scale=1.0">
#             #     <title>í¬ë¡¤ë§ ë°ì´í„°</title>
#             # </head>
#             # <body>
#             #     {contents_div}
#             # </body>
#             # </html>
#             # """

#             # # HTML íŒŒì¼ë¡œ ì €ì¥
#             # with open("crawled_content.html", "w", encoding="utf-8") as file:
#             #     file.write(html_content)
#             BoardData.objects.create(tag=str(contents_div))
#             print(str(contents_div))
#             print("\n:í°ìƒ‰_í™•ì¸_í‘œì‹œ: í¬ë¡¤ë§ ë° ì €ì¥ ì™„ë£Œ!")
#             print("âœ… HTML íŒŒì¼ ì €ì¥ ì™„ë£Œ! (crawled_content.html)")
#         else:
#             print("âš ï¸ 'contents' IDë¥¼ ê°€ì§„ divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#     else:
#         print(f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")

# # ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# # crawl_and_save('')  # ì›í•˜ëŠ” ì¸ìë¥¼ ì „ë‹¬í•´ì„œ ì‹¤í–‰
